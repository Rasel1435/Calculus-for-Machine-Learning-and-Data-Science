{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAt-K2qgcIou"
   },
   "source": [
    "# Optimization Using Gradient Descent: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZYK-0rin5x7"
   },
   "source": [
    "In this assignment, you will build a simple linear regression model to predict sales based on TV marketing expenses. You will investigate three different approaches to this problem. You will use `NumPy` and `Scikit-Learn` linear regression models, as well as construct and optimize the sum of squares cost function with gradient descent from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- [ 1 - Open the Dataset and State the Problem](#1)\n",
    "  - [ Exercise 1](#ex01)\n",
    "- [ 2 - Linear Regression in Python with `NumPy` and `Scikit-Learn`](#2)\n",
    "  - [ 2.1 - Linear Regression with `NumPy`](#2.1)\n",
    "    - [ Exercise 2](#ex02)\n",
    "  - [ 2.2 - Linear Regression with `Scikit-Learn`](#2.2)\n",
    "    - [ Exercise 3](#ex03)\n",
    "    - [ Exercise 4](#ex04)\n",
    "- [ 3 - Linear Regression using Gradient Descent](#3)\n",
    "  - [ Exercise 5](#ex05)\n",
    "  - [ Exercise 6](#ex06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n",
    "\n",
    "Load the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# A library for programmatic plot generation.\n",
    "import matplotlib.pyplot as plt\n",
    "# A library for data manipulation and analysis.\n",
    "import pandas as pd\n",
    "# LinearRegression from sklearn.\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the unit tests defined for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import w2_unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Open the Dataset and State the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will build a linear regression model for a simple [Kaggle dataset](https://www.kaggle.com/code/devzohaib/simple-linear-regression/notebook), saved in a file `data/tvmarketing.csv`. The dataset has only two fields: TV marketing expenses (`TV`) and sales amount (`Sales`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex01'></a>\n",
    "### Exercise 1\n",
    "\n",
    "Use `pandas` function `pd.read_csv` to open the .csv file the from the `path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "path = \"data/tvmarketing.csv\"\n",
    "\n",
    "### START CODE HERE ### (~ 1 line of code)\n",
    "adv = pd.read_csv(path)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Sales\n",
       "0  230.1   22.1\n",
       "1   44.5   10.4\n",
       "2   17.2    9.3\n",
       "3  151.5   18.5\n",
       "4  180.8   12.9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print some part of the dataset.\n",
    "adv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__ \n",
    "\n",
    "```Python\n",
    "\tTV\tSales\n",
    "0\t230.1\t22.1\n",
    "1\t44.5\t10.4\n",
    "2\t17.2\t9.3\n",
    "3\t151.5\t18.5\n",
    "4\t180.8\t12.9\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_load_data(adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` has a function to make plots from the DataFrame fields. By default, matplotlib is used at the backend. Let's use it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='TV', ylabel='Sales'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "adv.plot(x='TV', y='Sales', kind='scatter', c='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this dataset to solve a simple problem with linear regression: given a TV marketing budget, predict sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Linear Regression in Python with `NumPy` and `Scikit-Learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the required field of the DataFrame into variables `X` and `Y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "X = adv['TV']\n",
    "Y = adv['Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.1'></a>\n",
    "### 2.1 - Linear Regression with `NumPy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the function `np.polyfit(x, y, deg)` to fit a polynomial of degree `deg` to points $(x, y)$, minimising the sum of squared errors. You can read more in the [documentation](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html). Taking `deg = 1` you can obtain the slope `m` and the intercept `b` of the linear regression line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression with NumPy. Slope: 0.04753664043301978. Intercept: 7.032593549127698\n"
     ]
    }
   ],
   "source": [
    "m_numpy, b_numpy = np.polyfit(X, Y, 1)\n",
    "\n",
    "print(f\"Linear regression with NumPy. Slope: {m_numpy}. Intercept: {b_numpy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: [`NumPy` documentation](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html) suggests the [`Polynomial.fit` class method](https://numpy.org/doc/stable/reference/generated/numpy.polynomial.polynomial.Polynomial.fit.html#numpy.polynomial.polynomial.Polynomial.fit) as recommended for new code as it is more stable numerically. But in this simple example, you can stick to the `np.polyfit` function for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex02'></a>\n",
    "### Exercise 2\n",
    "\n",
    "Make predictions substituting the obtained slope and intercept coefficients into the equation $Y = mX + b$, given an array of $X$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# This is organised as a function only for grading purposes.\n",
    "def pred_numpy(m, b, X):\n",
    "    ### START CODE HERE ### (~ 1 line of code)\n",
    "    Y = m*X + b\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV marketing expenses:\n",
      "[ 50 120 280]\n",
      "Predictions of sales using NumPy linear regression:\n",
      "[ 9.40942557 12.7369904  20.34285287]\n"
     ]
    }
   ],
   "source": [
    "X_pred = np.array([50, 120, 280])\n",
    "Y_pred_numpy = pred_numpy(m_numpy, b_numpy, X_pred)\n",
    "\n",
    "print(f\"TV marketing expenses:\\n{X_pred}\")\n",
    "print(f\"Predictions of sales using NumPy linear regression:\\n{Y_pred_numpy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__ \n",
    "\n",
    "```Python\n",
    "TV marketing expenses:\n",
    "[ 50 120 280]\n",
    "Predictions of sales using NumPy linear regression:\n",
    "[ 9.40942557 12.7369904  20.34285287]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_pred_numpy(pred_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.2'></a>\n",
    "### 2.2 - Linear Regression with `Scikit-Learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Scikit-Learn` is an open-source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities. `Scikit-learn` provides dozens of built-in machine learning algorithms and models, called **estimators**. Each estimator can be fitted to some data using its `fit` method. Full documentation can be found [here](https://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an estimator object for a linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "lr_sklearn = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimator can learn from data calling the `fit` function. However, trying to run the following code you will get an error, as the data needs to be reshaped into 2D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X array: (200,)\n",
      "Shape of Y array: (200,)\n",
      "Expected 2D array, got 1D array instead:\n",
      "array=[230.1  44.5  17.2 151.5 180.8   8.7  57.5 120.2   8.6 199.8  66.1 214.7\n",
      "  23.8  97.5 204.1 195.4  67.8 281.4  69.2 147.3 218.4 237.4  13.2 228.3\n",
      "  62.3 262.9 142.9 240.1 248.8  70.6 292.9 112.9  97.2 265.6  95.7 290.7\n",
      " 266.9  74.7  43.1 228.  202.5 177.  293.6 206.9  25.1 175.1  89.7 239.9\n",
      " 227.2  66.9 199.8 100.4 216.4 182.6 262.7 198.9   7.3 136.2 210.8 210.7\n",
      "  53.5 261.3 239.3 102.7 131.1  69.   31.5 139.3 237.4 216.8 199.1 109.8\n",
      "  26.8 129.4 213.4  16.9  27.5 120.5   5.4 116.   76.4 239.8  75.3  68.4\n",
      " 213.5 193.2  76.3 110.7  88.3 109.8 134.3  28.6 217.7 250.9 107.4 163.3\n",
      " 197.6 184.9 289.7 135.2 222.4 296.4 280.2 187.9 238.2 137.9  25.   90.4\n",
      "  13.1 255.4 225.8 241.7 175.7 209.6  78.2  75.1 139.2  76.4 125.7  19.4\n",
      " 141.3  18.8 224.  123.1 229.5  87.2   7.8  80.2 220.3  59.6   0.7 265.2\n",
      "   8.4 219.8  36.9  48.3  25.6 273.7  43.  184.9  73.4 193.7 220.5 104.6\n",
      "  96.2 140.3 240.1 243.2  38.   44.7 280.7 121.  197.6 171.3 187.8   4.1\n",
      "  93.9 149.8  11.7 131.7 172.5  85.7 188.4 163.5 117.2 234.5  17.9 206.8\n",
      " 215.4 284.3  50.  164.5  19.6 168.4 222.4 276.9 248.4 170.2 276.7 165.6\n",
      " 156.6 218.5  56.2 287.6 253.8 205.  139.5 191.1 286.   18.7  39.5  75.5\n",
      "  17.2 166.8 149.7  38.2  94.2 177.  283.6 232.1].\n",
      "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of X array: {X.shape}\")\n",
    "print(f\"Shape of Y array: {Y.shape}\")\n",
    "\n",
    "try:\n",
    "    lr_sklearn.fit(X, Y)\n",
    "except ValueError as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can increase the dimension of the array by one with `reshape` function, or there is another another way to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of new X array: (200, 1)\n",
      "Shape of new Y array: (200, 1)\n"
     ]
    }
   ],
   "source": [
    "X_sklearn = X[:, np.newaxis]\n",
    "Y_sklearn = Y[:, np.newaxis]\n",
    "\n",
    "print(f\"Shape of new X array: {X_sklearn.shape}\")\n",
    "print(f\"Shape of new Y array: {Y_sklearn.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex03'></a>\n",
    "### Exercise 3\n",
    "\n",
    "Fit the linear regression model passing `X_sklearn` and `Y_sklearn` arrays into the function `lr_sklearn.fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### START CODE HERE ### (~ 1 line of code)\n",
    "lr_sklearn.fit(X_sklearn, Y_sklearn)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression using Scikit-Learn. Slope: [[0.04753664]]. Intercept: [7.03259355]\n"
     ]
    }
   ],
   "source": [
    "m_sklearn = lr_sklearn.coef_\n",
    "b_sklearn = lr_sklearn.intercept_\n",
    "\n",
    "print(f\"Linear regression using Scikit-Learn. Slope: {m_sklearn}. Intercept: {b_sklearn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__ \n",
    "\n",
    "```Python\n",
    "Linear regression using Scikit-Learn. Slope: [[0.04753664]]. Intercept: [7.03259355]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_sklearn_fit(lr_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you have got the same result as with the `NumPy` function `polyfit`. Now, to make predictions it is convenient to use `Scikit-Learn` function `predict`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex04'></a>\n",
    "### Exercise 4\n",
    "\n",
    "\n",
    "Increase the dimension of the $X$ array using the function `np.newaxis` (see an example above) and pass the result to the `lr_sklearn.predict` function to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# This is organised as a function only for grading purposes.\n",
    "def pred_sklearn(X, lr_sklearn):\n",
    "    ### START CODE HERE ### (~ 2 lines of code)\n",
    "    X_2D = X[:, np.newaxis]\n",
    "    Y = lr_sklearn.predict(X_2D)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV marketing expenses:\n",
      "[ 50 120 280]\n",
      "Predictions of sales using Scikit_Learn linear regression:\n",
      "[[ 9.40942557 12.7369904  20.34285287]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred_sklearn = pred_sklearn(X_pred, lr_sklearn)\n",
    "\n",
    "print(f\"TV marketing expenses:\\n{X_pred}\")\n",
    "print(f\"Predictions of sales using Scikit_Learn linear regression:\\n{Y_pred_sklearn.T}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__ \n",
    "\n",
    "```Python\n",
    "TV marketing expenses:\n",
    "[ 50 120 280]\n",
    "Predictions of sales using Scikit_Learn linear regression:\n",
    "[[ 9.40942557 12.7369904  20.34285287]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_sklearn_predict(pred_sklearn, lr_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot the linear regression line and the predictions by running the following code. The regression line is red and the predicted points are blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fed50c39ac0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(8,5))\n",
    "ax.plot(X, Y, 'o', color='green')\n",
    "ax.set_xlabel('TV')\n",
    "ax.set_ylabel('Sales')\n",
    "\n",
    "ax.plot(X, m_sklearn[0][0]*X+b_sklearn[0], color='red')\n",
    "ax.plot(X_pred, Y_pred_sklearn, 'o', color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Linear Regression using Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to fit the models automatically are convenient to use, but for an in-depth understanding of the model and the maths behind it is good to implement an algorithm by yourself. Let's try to find linear regression coefficients $m$ and $b$, by minimising the difference between original values $y^{(i)}$ and predicted values $\\hat{y}^{(i)}$ with the **loss function** $L\\left(w, b\\right)  = \\frac{1}{2}\\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2$ for each of the training examples. Division by $2$ is taken just for scaling purposes, you will see the reason below, calculating partial derivatives.\n",
    "\n",
    "To compare the resulting vector of the predictions $\\hat{Y}$ with the vector $Y$ of original values $y^{(i)}$, you can take an average of the loss function values for each of the training examples:\n",
    "\n",
    "$$E\\left(m, b\\right) = \\frac{1}{2n}\\sum_{i=1}^{n} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2 = \n",
    "\\frac{1}{2n}\\sum_{i=1}^{n} \\left(mx^{(i)}+b - y^{(i)}\\right)^2,\\tag{1}$$\n",
    "\n",
    "where $n$ is a number of data points. This function is called the sum of squares **cost function**. To use gradient descent algorithm, calculate partial derivatives as:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial E }{ \\partial m } &= \n",
    "\\frac{1}{n}\\sum_{i=1}^{n} \\left(mx^{(i)}+b - y^{(i)}\\right)x^{(i)},\\\\\n",
    "\\frac{\\partial E }{ \\partial b } &= \n",
    "\\frac{1}{n}\\sum_{i=1}^{n} \\left(mx^{(i)}+b - y^{(i)}\\right),\n",
    "\\tag{2}\\end{align}\n",
    "\n",
    "and update the parameters iteratively using the expressions\n",
    "\n",
    "\\begin{align}\n",
    "m &= m - \\alpha \\frac{\\partial E }{ \\partial m },\\\\\n",
    "b &= b - \\alpha \\frac{\\partial E }{ \\partial b },\n",
    "\\tag{3}\\end{align}\n",
    "\n",
    "where $\\alpha$ is the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original arrays `X` and `Y` have different units. To make gradient descent algorithm efficient, you need to bring them to the same units. A common approach to it is called **normalization**: substract the mean value of the array from each of the elements in the array and divide them by standard deviation (a statistical measure of the amount of dispersion of a set of values). If you are not familiar with mean and standard deviation, do not worry about this for now - this is covered in the next Course of Specialization.\n",
    "\n",
    "Normalization is not compulsory - gradient descent would work without it. But due to different units of `X` and `Y`, the cost function will be much steeper. Then you would need to take a significantly smaller learning rate $\\alpha$, and the algorithm will require thousands of iterations to converge instead of a few dozens. Normalization helps to increase the efficiency of the gradient descent algorithm.\n",
    "\n",
    "Normalization is implemented in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "X_norm = (X - np.mean(X))/np.std(X)\n",
    "Y_norm = (Y - np.mean(Y))/np.std(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define cost function according to the equation $(1)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def E(m, b, X, Y):\n",
    "    return 1/(2*len(Y))*np.sum((m*X + b - Y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex05'></a>\n",
    "### Exercise 5\n",
    "\n",
    "\n",
    "Define functions `dEdm` and `dEdb` to calculate partial derivatives according to the equations $(2)$. This can be done using vector form of the input data `X` and `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def dEdm(m, b, X, Y):\n",
    "    ### START CODE HERE ### (~ 1 line of code)\n",
    "    # Use the following line as a hint, replacing all None.\n",
    "    res = (1/len(X)) * np.dot(-X, (Y - (m * X + b)))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return res\n",
    "    \n",
    "\n",
    "def dEdb(m, b, X, Y):\n",
    "    ### START CODE HERE ### (~ 1 line of code)\n",
    "    # Replace None writing the required expression fully.\n",
    "    res = (1/len(X)) * np.sum(-Y + (m * X + b))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7822244248616067\n",
      "5.151434834260726e-16\n",
      "0.21777557513839355\n",
      "5.000000000000001\n"
     ]
    }
   ],
   "source": [
    "print(dEdm(0, 0, X_norm, Y_norm))\n",
    "print(dEdb(0, 0, X_norm, Y_norm))\n",
    "print(dEdm(1, 5, X_norm, Y_norm))\n",
    "print(dEdb(1, 5, X_norm, Y_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__ \n",
    "\n",
    "```Python\n",
    "-0.7822244248616067\n",
    "5.098005351200641e-16\n",
    "0.21777557513839355\n",
    "5.000000000000002\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_partial_derivatives(dEdm, dEdb, X_norm, Y_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex06'></a>\n",
    "### Exercise 6\n",
    "\n",
    "\n",
    "Implement gradient descent using expressions $(3)$:\n",
    "\\begin{align}\n",
    "m &= m - \\alpha \\frac{\\partial E }{ \\partial m },\\\\\n",
    "b &= b - \\alpha \\frac{\\partial E }{ \\partial b },\n",
    "\\end{align}\n",
    "\n",
    "where $\\alpha$ is the `learning_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def gradient_descent(dEdm, dEdb, m, b, X, Y, learning_rate = 0.001, num_iterations = 1000, print_cost=False):\n",
    "    for iteration in range(num_iterations):\n",
    "        ### START CODE HERE ### (~ 2 lines of code)\n",
    "        m_new = m - learning_rate * dEdm(m, b, X, Y)\n",
    "        b_new = b - learning_rate * dEdb(m, b, X, Y)\n",
    "        ### END CODE HERE ###\n",
    "        m = m_new\n",
    "        b = b_new\n",
    "        if print_cost:\n",
    "            print (f\"Cost after iteration {iteration}: {E(m, b, X, Y)}\")\n",
    "        \n",
    "    return m, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.49460408269589495, -3.4915181856831644e-16)\n",
      "(0.9791767513915026, 4.521910375044022)\n"
     ]
    }
   ],
   "source": [
    "print(gradient_descent(dEdm, dEdb, 0, 0, X_norm, Y_norm))\n",
    "print(gradient_descent(dEdm, dEdb, 1, 5, X_norm, Y_norm, learning_rate = 0.01, num_iterations = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__ \n",
    "\n",
    "```Python\n",
    "(0.49460408269589495, -3.489285249624889e-16)\n",
    "(0.9791767513915026, 4.521910375044022)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_gradient_descent(gradient_descent, dEdm, dEdb, X_norm, Y_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the gradient descent method starting from the initial point $\\left(m_0, b_0\\right)=\\left(0, 0\\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.20629997559196597\n",
      "Cost after iteration 1: 0.19455197461564464\n",
      "Cost after iteration 2: 0.19408205457659178\n",
      "Cost after iteration 3: 0.19406325777502967\n",
      "Cost after iteration 4: 0.19406250590296714\n",
      "Cost after iteration 5: 0.19406247582808467\n",
      "Cost after iteration 6: 0.19406247462508938\n",
      "Cost after iteration 7: 0.19406247457696957\n",
      "Cost after iteration 8: 0.19406247457504477\n",
      "Cost after iteration 9: 0.19406247457496775\n",
      "Cost after iteration 10: 0.1940624745749647\n",
      "Cost after iteration 11: 0.19406247457496456\n",
      "Cost after iteration 12: 0.19406247457496456\n",
      "Cost after iteration 13: 0.19406247457496456\n",
      "Cost after iteration 14: 0.19406247457496456\n",
      "Cost after iteration 15: 0.19406247457496456\n",
      "Cost after iteration 16: 0.19406247457496456\n",
      "Cost after iteration 17: 0.19406247457496456\n",
      "Cost after iteration 18: 0.19406247457496456\n",
      "Cost after iteration 19: 0.19406247457496456\n",
      "Cost after iteration 20: 0.19406247457496456\n",
      "Cost after iteration 21: 0.19406247457496456\n",
      "Cost after iteration 22: 0.19406247457496456\n",
      "Cost after iteration 23: 0.19406247457496456\n",
      "Cost after iteration 24: 0.19406247457496456\n",
      "Cost after iteration 25: 0.19406247457496456\n",
      "Cost after iteration 26: 0.19406247457496456\n",
      "Cost after iteration 27: 0.19406247457496456\n",
      "Cost after iteration 28: 0.19406247457496456\n",
      "Cost after iteration 29: 0.19406247457496456\n",
      "Gradient descent result: m_min, b_min = 0.7822244248616068, -6.075140390748858e-16\n"
     ]
    }
   ],
   "source": [
    "m_initial = 0; b_initial = 0; num_iterations = 30; learning_rate = 1.2\n",
    "m_gd, b_gd = gradient_descent(dEdm, dEdb, m_initial, b_initial, \n",
    "                              X_norm, Y_norm, learning_rate, num_iterations, print_cost=True)\n",
    "\n",
    "print(f\"Gradient descent result: m_min, b_min = {m_gd}, {b_gd}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, that the initial datasets were normalized. To make the predictions, you need to normalize `X_pred` array, calculate `Y_pred` with the linear regression coefficients `m_gd`, `b_gd` and then **denormalize** the result (perform the reverse process of normalization):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV marketing expenses:\n",
      "[ 50 120 280]\n",
      "Predictions of sales using Scikit_Learn linear regression:\n",
      "[[ 9.40942557 12.7369904  20.34285287]]\n",
      "Predictions of sales using Gradient Descent:\n",
      "[ 9.40942557 12.7369904  20.34285287]\n"
     ]
    }
   ],
   "source": [
    "X_pred = np.array([50, 120, 280])\n",
    "# Use the same mean and standard deviation of the original training array X\n",
    "X_pred_norm = (X_pred - np.mean(X))/np.std(X)\n",
    "Y_pred_gd_norm = m_gd * X_pred_norm + b_gd\n",
    "# Use the same mean and standard deviation of the original training array Y\n",
    "Y_pred_gd = Y_pred_gd_norm * np.std(Y) + np.mean(Y)\n",
    "\n",
    "print(f\"TV marketing expenses:\\n{X_pred}\")\n",
    "print(f\"Predictions of sales using Scikit_Learn linear regression:\\n{Y_pred_sklearn.T}\")\n",
    "print(f\"Predictions of sales using Gradient Descent:\\n{Y_pred_gd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have gotten similar results as in the previous sections. \n",
    "\n",
    "Well done! Now you know how gradient descent algorithm can be applied to train a real model. Re-producing results manually for a simple case should give you extra confidence that you understand what happends under the hood of commonly used functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C1_W1_Assignment_Solution.ipynb",
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "AI4MC1-1"
   ]
  },
  "grader_version": "1",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "478841ab876a4250505273c8a697bbc1b6b194054b009c227dc606f17fb56272"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
